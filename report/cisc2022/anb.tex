\section{Analysis and Benchmark}

The proposed scheme profiles an image of containers via cgroup and namespace
and uses the seccomp mechanism to force the policy in the kernel.
We will analyze how the proposed scheme protects our system when hackers land
into the container, and we profile the concurrent costs of this
mechanism.

\subsection{Analysis}
Our defense level is at the kernel level, but the virtual machine's
defense level is at the instruction level. Because we do not impose any
restrictions on the CPU instruction set, nor isolate the host operating system.
Although the defense level at the instruction set seems to be more efficient,
the virtual machine's protection consumes more time. We will show that in Fig \ref{conc}.

In the health and medical information exchange system, the health and
medical information we protect is specialized and fixed. For example,
we do not have any attack on parsing some format string,
%\footnote{\url{https://owasp.org/www-community/attacks/Format_string_attack}},
which is an exploit of bypassing the ASLR\footnote{\url{https://lwn.net/Articles/569635/}}.

So the proposed scheme can remove some redundant system calls that could
limit the possibility of hacker exploitation. Therefore, we can protect
the user's data from being hacked in the information exchange system.

\subsubsection{Attacking Surface}
We discuessed the five stages of malware in \ref{Five_stage_of_malware}. We analyzed
three possible attacking scenarios for hackers in this subsubsection.

\subsubsection{Zero-day or One-day Vulnerability}
Assuming that the hacker does not have system administration privileges,
but exploits the vulnerability of the health information exchange system
(IBM/FHIR server) to conduct malicious attacks. We can also use the same
behavioral filter to filter the attack.
For example, the log4j attack (CVE-2021-44228), which has been a published
vulnerability while we researching this container security issue.
Before our research, this vulnerability existed in IBM/FHIR container server.
%\footnote{\url{https://github.com/IBM/FHIR/issues/3156}}.
When a user turns the "export to parquet" feature on, it would
bring in much of Apache Spark which leads to enable the vulnerable log4j.

However, unfortunately, we have to admit that the defenses we propose cannot
withstand this log4j attack. The IBM/FHIR server itself can enable such a mechanism,
so actions using log4j are invoked at build time. We would admit these
behaviors as normal behavior at the system-call filter level.

%\subsubsection{Breaking protection rings}

%\begin{figure}
%    \centering
%    \includegraphics[width=.5\textwidth]{src/ring.jpeg}
%    \blodcaption{Intel Architecture Hardware View}
%    \label{ring}
%\end{figure}

%Within the architecture of a computer system, a protection ring
%\footnote{\url{https://www.eff.org/deeplinks/2017/05/intels-management-engine-security-hazard-and-users-need-way-disable-it}}
%\footnote{\href{https://medium.com/swlh/negative-rings-in-intel-architecture-the-security-threats-youve-probably-never-heard-of-d725a4b6f831}
%    {Negative Rings in Intel Architecture: The Security Threats That Youâ€™ve Probably Never Heard Of}}
%, is one of two or more
%hierarchical levels or layers of privilege. Which was proposed by the Multics
%operating system \cite{6234805}.

\subsubsection{Time Consuming}
\textcite{KOZHIRBAYEV2017175} showed that there is basically no
statistical difference between container and host environment.
This is completely in line with our perception of a container,
which is said that containers are isolated processes.

According to our experiments, to do a statict that the integration tests and unit
tests were executed on IBM/FHIR server 4.9.0, and the system calls,
and system events we collected are shown in Fig. \ref{hist}.

Fig. \ref{hist} illustrates the FHIR server's all system calls in
BoSC \cite{1495942} and the number of times that had been called.
\begin{figure}
    \centering
    \includegraphics[width=.5\textwidth]{src/hist.png}
    \blodcaption{All the system calls from the FHIR Server}
    \label{hist}
\end{figure}
Among them, we can find that the most used is the `stat' system call.
To benchmark, it is found that the discussion of container performance testing is less
focused on the requirement of parallel multiplexing
\cite{7371699,KOZHIRBAYEV2017175,7095802,234857}. And it is a more
important issue for the server's high multiplexing performance service client.
Which result is same as our tesing results.

\subsubsection{Latency}
Fig. \ref{conc} is the concurrent processes transporting time
difference in a container and a virtual machine.
\textcite{234857} showed that the latency of opening and closing files
is no significant difference between native and runc. But there was 12 times
faster than the gVisor with internal access. Although our IBM/FHIR server
cannot be executed in gVisor, it is the same in native and runc with no
significant difference.

\textcite{7095802} showed the relation between the throughput and the concurrency,
where both have the transaction's upper bound cost in MySQL. The overhead of KVM is
much higher, above 40\% in all measured cases. We think that there is a driver
buffering bottleneck in the hypervisor of KVM in ring 0.

Hence, we compare the time lag between Ubuntu 20.04 in QEMU/KVM in Archlinux
and native Alpine container in Archlinux on concurrent requests.
A phenomenon we found is that the latency curve of a virtual
machine seems to be different in complexity from that of a native container.

\begin{figure}
    \centering
    \includegraphics[width=.5\textwidth]{src/concurrent.png}
    \blodcaption{Concurrent processes transporting time}
    \label{conc}
\end{figure}
